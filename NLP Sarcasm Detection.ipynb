{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pp68FAQf9aMN"
   },
   "source": [
    "# Sarcasm Detection\n",
    " **Acknowledgement**\n",
    "\n",
    "Misra, Rishabh, and Prahal Arora. \"Sarcasm Detection using Hybrid Neural Network.\" arXiv preprint arXiv:1908.07414 (2019).\n",
    "\n",
    "**Required Files given in below link.**\n",
    "\n",
    "https://drive.google.com/drive/folders/1xUnF35naPGU63xwRDVGc-DkZ3M8V5mMk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S3Wj_mIZ8S3K"
   },
   "source": [
    "## Install `Tensorflow2.0` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "colab_type": "code",
    "id": "jW2Uk8otQvi8",
    "outputId": "2b9adbec-9f88-4a0d-fb17-22eaf6aa5280"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.0.0\n",
      "  Using cached https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.9.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.34.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.2.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
      "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.29.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.10.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.18.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (47.1.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.7.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.10.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.6.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.8)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.8)\n",
      "Installing collected packages: tensorflow\n",
      "Successfully installed tensorflow-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!!pip uninstall tensorflow\n",
    "!pip install tensorflow==2.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EbKRpnUXSQ8F"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9kv9tyJ77eF"
   },
   "source": [
    "## Get Required Files from Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "D0O_n6OIEVyL",
    "outputId": "970d6f26-b604-43f9-818e-82e755ae19d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0mgRpOvFMjKR"
   },
   "outputs": [],
   "source": [
    "#Set your project path \n",
    "project_path =  '/content/drive/My Drive/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WXYwajPeQbRq"
   },
   "source": [
    "#**## Reading and Exploring Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vAk6BRUh8CqL"
   },
   "source": [
    "## Read Data \"Sarcasm_Headlines_Dataset.json\". Explore the data and get  some insights about the data. ( 4 marks)\n",
    "Hint - As its in json format you need to use pandas.read_json function. Give paraemeter lines = True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "bBWZr8Q3wVbE",
    "outputId": "729995c7-3b7e-4ed5-d171-033649286591"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  ... is_sarcastic\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...  ...            0\n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...  ...            0\n",
       "2  https://local.theonion.com/mom-starting-to-fea...  ...            1\n",
       "3  https://politics.theonion.com/boehner-just-wan...  ...            1\n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...  ...            0\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "df=pd.read_json(os.path.join(project_path,'Sarcasm_Headlines_Dataset.json'),lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "8gg95DTfwVb6",
    "outputId": "6b19b4b2-9306-4767-d19d-0d1972d129ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26709 entries, 0 to 26708\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   article_link  26709 non-null  object\n",
      " 1   headline      26709 non-null  object\n",
      " 2   is_sarcastic  26709 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 626.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "Sv6f7JYVwVcL",
    "outputId": "3f573577-ac8b-41e3-8af9-30c49cd34441"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26709, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26709.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.438953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.496269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       is_sarcastic\n",
       "count  26709.000000\n",
       "mean       0.438953\n",
       "std        0.496269\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        1.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "tqfzdgyYwVca",
    "outputId": "cdc9c099-7652-46bd-dd91-ae1265b57f42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14985\n",
       "1    11724\n",
       "Name: is_sarcastic, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_sarcastic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "5ZxS2Om5wVci",
    "outputId": "1d46dd3f-864d-4c1c-b88d-34eef28fe790"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb46b8c64a8>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df['is_sarcastic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kKQrpxTIwVco"
   },
   "source": [
    "### Observations:\n",
    "\n",
    "1)The dataset has 26709 enteries each associated with 3 features: article_link, headline and is_sarcastic\n",
    "2)The number of headlines that are 'not sarcastic (0)' outnumber the ones that are categorised as 'sarcastic (1)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "OEBomISDwVcp",
    "outputId": "125d2dc6-7796-4b58-a268-d6173344efba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues secret black c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>roseanne revival catches thorny political mood...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting fear sons web series closest thin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner wants wife listen come alternative deb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>jk rowling wishes snape happy birthday magical...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  ... is_sarcastic\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...  ...            0\n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...  ...            0\n",
       "2  https://local.theonion.com/mom-starting-to-fea...  ...            1\n",
       "3  https://politics.theonion.com/boehner-just-wan...  ...            1\n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...  ...            0\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text preprocessing: Remove punctuations and stopwords from 'headline'\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words=set(stopwords.words('english'))\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def data_preprocess(text):\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = word_tokenize(text)\n",
    "    text = [w for w in text if not w in stop_words]   \n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "df['headline']=df['headline'].apply(data_preprocess)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z6pXf7A78E2H"
   },
   "source": [
    "## Drop `article_link` from dataset. ( 2 marks)\n",
    "As we only need headline text data and is_sarcastic column for this project. We can drop artical link column here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "FR3lV1gUwVcw",
    "outputId": "802422e6-1b86-43d3-fbed-4de62d32791f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues secret black c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roseanne revival catches thorny political mood...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting fear sons web series closest thin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner wants wife listen come alternative deb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jk rowling wishes snape happy birthday magical...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues secret black c...             0\n",
       "1  roseanne revival catches thorny political mood...             0\n",
       "2  mom starting fear sons web series closest thin...             1\n",
       "3  boehner wants wife listen come alternative deb...             1\n",
       "4  jk rowling wishes snape happy birthday magical...             0"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop(['article_link'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0h6IOxU8OdH"
   },
   "source": [
    "## Get the Length of each line and find the maximum length. ( 4 marks)\n",
    "As different lines are of different length. We need to pad the our sequences using the max length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "BRAsChZAQmr3",
    "outputId": "ecb7dda0-5b7a-4e59-a367-8e36ab118333"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues secret black c...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roseanne revival catches thorny political mood...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting fear sons web series closest thin...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner wants wife listen come alternative deb...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jk rowling wishes snape happy birthday magical...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  ...  headline_length\n",
       "0  former versace store clerk sues secret black c...  ...               10\n",
       "1  roseanne revival catches thorny political mood...  ...                8\n",
       "2  mom starting fear sons web series closest thin...  ...                9\n",
       "3  boehner wants wife listen come alternative deb...  ...                8\n",
       "4  jk rowling wishes snape happy birthday magical...  ...                8\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['headline_length']=df.apply(lambda x: len(x['headline'].split()), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "M5T8MQwbwVdA",
    "outputId": "756f9307-3915-41b3-a700-7a76e9e83905"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['headline_length'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5sFOITxswVdI"
   },
   "source": [
    "### Observation:\n",
    "\n",
    "The maximum length or the maximum number of words is 27. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "7N0AG19JwVdK",
    "outputId": "262b2199-856e-4e03-9393-a02b6f82ca92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues secret black c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roseanne revival catches thorny political mood...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues secret black c...             0\n",
       "1  roseanne revival catches thorny political mood...             0"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['headline_length'], axis=1, inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VPPd0YuPXi2M"
   },
   "source": [
    "#**## Modelling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "35abKfRx8as3"
   },
   "source": [
    "## Import required modules required for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVel73hYEV4r"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ziybaD1RdD9"
   },
   "source": [
    "# Set Different Parameters for the model. ( 2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jPw9gAN_EV6m"
   },
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "maxlen = 27\n",
    "embedding_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9abSe-bM8fn9"
   },
   "source": [
    "## Apply Keras Tokenizer of headline column of your data.  ( 4 marks)\n",
    "Hint - First create a tokenizer instance using Tokenizer(num_words=max_features) \n",
    "And then fit this tokenizer instance on your data column df['headline'] using .fit_on_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T9Ad26HfTFMS"
   },
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(df['headline'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Ffi63KsST3P"
   },
   "source": [
    "# Define X and y for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "wnjxBdqmSS4s",
    "outputId": "ab3fdd10-9524-4f46-ea6f-3092910e5936"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 26709\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0  204  692 3437 2129  267   33 2026 2397 8167]\n",
      "Number of Labels:  26709\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(df['headline'])\n",
    "X = pad_sequences(X, maxlen = maxlen)\n",
    "y = np.asarray(df['is_sarcastic'])\n",
    "\n",
    "print(\"Number of Samples:\", len(X))\n",
    "print(X[0])\n",
    "print(\"Number of Labels: \", len(y))\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJLyKg-98rH_"
   },
   "source": [
    "## Get the Vocabulary size ( 2 marks)\n",
    "Hint : You can use tokenizer.word_index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "q-2w0gHEUUIo",
    "outputId": "89f64122-e974-403b-ca43-230b9e8b93f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28276\n"
     ]
    }
   ],
   "source": [
    "word_index=tokenizer.word_index\n",
    "num_words = len(word_index)+1\n",
    "print(num_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5hjeMi40XcB1"
   },
   "source": [
    "#**## Word Embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bUF1TuQa8ux0"
   },
   "source": [
    "## Get Glove Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h7aycORIwVe8"
   },
   "outputs": [],
   "source": [
    "glove_file = project_path +\"glove.6B.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJLX_n2WMecA"
   },
   "outputs": [],
   "source": [
    "#Extract Glove embedding zip file\n",
    "from zipfile import ZipFile\n",
    "with ZipFile(glove_file, 'r') as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9IuXlu8-U3HG"
   },
   "source": [
    "# Get the Word Embeddings using Embedding file as given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elZ-T5aFGZmZ"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = './glove.6B.200d.txt'\n",
    "\n",
    "embeddings = {}\n",
    "for o in open(EMBEDDING_FILE, encoding='utf8'):\n",
    "    word = o.split(\" \")[0]\n",
    "    #print(word)\n",
    "    embd = o.split(\" \")[1:]\n",
    "    embd = np.asarray(embd, dtype='float32')\n",
    "    #print(embd)\n",
    "    embeddings[word] = embd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bTPxveDmVCrA"
   },
   "source": [
    "# Create a weight matrix for words in training docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xQgOhiywU9nU",
    "outputId": "3e2c9e5e-383c-466f-8c05-42d83acc7650"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28276, 200)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((num_words, 200))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "len(embeddings.values())\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7IbWuEX82Ra"
   },
   "source": [
    "## Create and Compile your Model  ( 7 marks)\n",
    "Hint - Use Sequential model instance and then add Embedding layer, Bidirectional(LSTM) layer, then dense and dropout layers as required. \n",
    "In the end add a final dense layer with sigmoid activation for binary classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "d7jhsSgYXG4l",
    "outputId": "2a322040-6e87-44da-95bb-b6bdc6d45589"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 27, 200)           5655200   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               336896    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 5,992,353\n",
      "Trainable params: 5,992,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import LSTM, Bidirectional, Dropout, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, output_dim=embedding_size, weights=[embedding_matrix], input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(units=128)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IJFMxZwMWoTw"
   },
   "source": [
    "# Fit your model with a batch size of 100 and validation_split = 0.2. and state the validation accuracy ( 5 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "ZpVkajCcWnRK",
    "outputId": "c2f0a62a-cc0a-478a-b2e4-4f27cbc80c81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "21367/21367 [==============================] - 71s 3ms/step - loss: 0.5057 - accuracy: 0.7467\n",
      "Epoch 2/5\n",
      "21367/21367 [==============================] - 70s 3ms/step - loss: 0.3389 - accuracy: 0.8526\n",
      "Epoch 3/5\n",
      "21367/21367 [==============================] - 70s 3ms/step - loss: 0.2468 - accuracy: 0.8962\n",
      "Epoch 4/5\n",
      "21367/21367 [==============================] - 69s 3ms/step - loss: 0.1763 - accuracy: 0.9301\n",
      "Epoch 5/5\n",
      "21367/21367 [==============================] - 69s 3ms/step - loss: 0.1234 - accuracy: 0.9535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb45fbb5748>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 5\n",
    "\n",
    "## Add your code here ##\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "model.fit(X_train,y_train, batch_size=batch_size, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "uhHazZP3wVgV",
    "outputId": "f7c6e2c3-f4e1-4bdd-ddc0-1c2e40564dc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5342/5342 [==============================] - 6s 1ms/step\n",
      "Accuracy: 82.07%\n",
      "Test Loss: 0.5552\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f%%' %(accuracy*100))\n",
    "print('Test Loss: %.4f' % (loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7PjFvSRAS9-l"
   },
   "source": [
    "### Conclusions:\n",
    "The dataset was fit using pretrained Glove Embedding with 200 faetures and LSTM architecture. The model gave an accuracy of 82%."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_Project_Sarcasm_Detection_Questions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
